\documentclass{article}
\usepackage{graphicx,fancyhdr,amsmath,amssymb,amsthm,subfig,url,hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm, algorithmicx, algpseudocode, graphicx, physics}
\usepackage{afterpage}
\usepackage{algorithm}
\usepackage{algpseudocode}


%----------------------- Macros and Definitions --------------------------

%%% FILL THIS OUT
\newcommand{\studentname}{Francis Zhang}
\newcommand{\suid}{xz3279}
\newcommand{\exerciseset}{Homework 2}
%%% END



\renewcommand{\theenumi}{\bf \Alph{enumi}}


%\theoremstyle{plain}


\fancypagestyle{plain}{}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[RO,LE]{\sffamily\bfseries\large Columbia University}
\fancyhead[LO,RE]{\sffamily\bfseries\large CSORE 4231 ANALYSIS OF ALGORITHMS I}
\fancyfoot[LO,RE]{\sffamily\bfseries\large \studentname:  \suid
}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}

\graphicspath{{figures/}}

%-------------------------------- Title ----------------------------------

\title{CSORE 4231 ANALYSIS OF ALGORITHMS I \exerciseset}
\author{\studentname  \qquad \suid}

%--------------------------------- Text ----------------------------------

\begin{document}
\maketitle

\section*{Problem 1}
\textbf{Mo’ Money Mo’ Problems.}\\
\textbf{(a)}  Consider the following game. There are \( n \) cards with the numbers \( 1, \ldots, n \) written on them, where each of the numbers \( 1, \ldots, n \) is written on exactly one of the cards. The cards are face down on the table, so we do not see their numbers. We turn over the cards one by one. Before turning each card, you guess the number written on the card; then you see the card, and you gain 1 dollar if you guess correctly and 0 if incorrectly. A random strategy is to guess in each step uniformly at random a number that has not appeared so far in the previous cards. What is the probability that the guess in the \( i^{th} \) step is correct?\\
\textbf{(b)} Using indicator random variables, show that the expected total number of dollars that you gain using the random strategy from part (a) is \( \Theta(\log n) \).\\
\textbf{(c)} CLRS 5.3-2\\
Professor Kelp decides to write a procedure that produces at random any permutation besides the identity permutation. He proposes the following procedure:

\begin{verbatim}
PERMUTE-WITHOUT-IDENTITY(A)
1   n = A.length
2   for i = 1 to n - 1
3       swap A[i] with A[RANDOM(i + 1, n)]
\end{verbatim}
Does this code do what Professor Kelp intends?\\
\textbf{(d)} CLRS 5.3-4\\
Professor Armstrong suggests the following procedure for generating a uniform random permutation:

\begin{verbatim}
PERMUTE-BY-CYCLIC(A)
1   n = A.length
2   let B[1..n] be a new array
3   offset = RANDOM(1, n)
4   for i = 1 to n
5       dest = i + offset
6       if dest > n
7           dest = dest - n
8       B[dest] = A[i]
9   return B
\end{verbatim}
Show that each element $A[i]$ has $\frac{1}{n}$ probability of winding up in any particular position in B. Then show that Professor Armstrong is mistaken by showing that the resulting permutation is not uniformly random.\\
\textbf{Solution:}\\
\textbf{(a)} As the random strategy used here is to guess in each step at random a number that has not appeared so far in the previous cards. When i = 1, the probability is $\frac{1}{n}$. When i = 2, as we know the first card, the probability is $\frac{1}{n-1}$... When i = i, the probability is $\frac{1}{n-i+1}$ as we know the previous $i-1$ cards, we are picking a number from the rest: $n-(i-1)= n-i+1$ cards.\\
\textbf{(b)} Recall from lecture, Let A be an event, the indicator variable $I\{A\}$ is defined by:
\begin{align*}
    I\{A\}=\left\{\begin{matrix} 
  &1 &\text{ if A occurs}\\  
  &0 &\text{ if A does not occur}
\end{matrix}\right. 
\end{align*}
Let $Y$ be a random variable that denotes the guess of the card. Let $X$ be the i.r.v. that counts earned dollars. $I$ represents the earned dollars. Then:
\begin{align*}
    I\{Y \text{ is i} \}=\left\{\begin{matrix} 
  &1 &\text{ if the card is actually i}\\  
  &0 &\text{ otherwise}
\end{matrix}\right. 
\end{align*}
\begin{align*}
    E[X] &= \sum_{i=1}^{n} Pr(Y \text{ is the card after turning})*\frac{1}{n-i+1}*1 + \sum_{i=0}^{n} Pr(Y \text{ is the card after turning})*\frac{n-i}{n-i+1}*0\\
    &= \sum_{i=0}^{n} Pr(Y \text{ is the card after turning})*\frac{1}{n-i+1}\\
    &= \frac{1}{n} + \frac{1}{n-1} + \text{...} + \frac{1}{1}\\
    &\approx \ln n = \Theta(\log n)
\end{align*}
\textbf{(c)}
NO. Consider the case where  $A=\{1,2,3\}$ . The permutation $\{3,2,1\}$ should be a possible output with some possibility, but cannot be generated by this code. Swap $A[1]$ with $A[2]$ we cannot make it, as $A[1]$ will never be altered after the first iteration. However, if we swap $A[1]$ and $A[3]$, we have $\{3,2,1\}$. During the second iteration, we have no choice but swap $A[2]$ and $A[3]$.\\
In general for $A.length = n$, where $A=\{1,2,3,...,n\}$, we can never have $\{n,...,1\}$ by this procedure. As to keep $A[1]=n$, we need to swap $A[1]$ and $A[n]$. Now $A[n]=1$. After those iterations, the last iteration must be $A[n-1]$ and $A[n]$, 1 just goes away.\\
\textbf{(d)} Analyzing each element $A[i]$ has $\frac{1}{n}$ probability of winding up in any particular position in B from the for loop. Starting from $i = 1$, as dest = $i$ + offset. Where offset = \texttt{RANDOM(1,n)}, as for each possibilities offset can be, those entries $1,...,n$ all have possibility $\frac{1}{n}$. So, for entries $2,...,n+1$ of dest, they all have possibility $\frac{1}{n}$. Also recall line 6 and 7 of the code, if dest $>$ n, then dest = dest - n. That makes the entry $n+1$ with possibility $\frac{1}{n}$ becomes the entry $1$ with possibility $\frac{1}{n}$. So, $A[1]$ has $\frac{1}{n}$ probability of winding up in any particular position in B. Similarly, in general all $i$'s entry if happens dest $>$ n, those bigger than $n$ entries would be minus $n$ and also have the same possibility $\frac{1}{n}$. That is ach element $A[i]$ has $\frac{1}{n}$ probability of winding up in any particular position in B.\\
However, it can still not showing the resulting permutation is uniformly random. We randomed offset, but in the loop, offset can not be changed. That is for $A=\{1,2,3\}$, B can only be consecutive 3 numbers from the array $123123123...123$, which is when offset = 1, $B=\{3,1,2\}$, offset = 2, $B=\{2,3,1\}$, and offset = 3, $B=\{1,2,3\}$. But no possibility of $B$ to become $\{1,3,2\}$, $\{2,1,3\}$, $\{3,2,1\}$.
\section*{Problem 2}
\textbf{Heapsort Correctness.} CLRS 6.4-2\\
Argue the correctness of HEAPSORT using the following loop invariant:

At the start of each iteration of the \textbf{for} loop of lines 2-5, the subarray $A[1..i]$ is a max-heap containing the $i$ smallest elements of $A[1..n]$, and the subarray $A[i + 1..n]$ contains the n - i largest elements of $A[1..n]$, sorted.\\
\textbf{Solution:\\}
\textbf{Initialization:} $i = A.length$, $A[1,...,n]$ do contain n smallest elements of A, $n - i= n - n = 0$ so we don't need to worry about subarray at the moment.\\
\textbf{Maintenance:} After applying BUILD-MAX-HEAP(A), $A[1]$ is the largest among $A[1,...,n]$, exchange with A[i] and put it out of the heap. After MAX-HEAPIFY(A,1), the new $A[1]$ is smaller than the old $A[1]$ and is greater then rest elements in the heap and the index is just 1 before the old $A[1]$. So it is $A[1,...i]$ represents unsorted i smallest elements of $A$, and $A[i+1,...,n]$ contains the $n-i$ largest elements of $A$, sorted.\\
\textbf{Termination:} When $i=2$, $A[1]$ exchange with $A[2]$ and put out of the heap. The loop terminates. The only $A[1]$ left in the heap and the sorted $A[2,...,n]$. Where $A[1]$ is smaller than $A[2,...,n]$. HEAPSORT works and sorted the entire $A$.\\

\section*{Problem 3}
\textbf{Merging sorted lists.} CLRS 6.5-9\\
Give an \( O(n \lg k) \)-time algorithm to merge \( k \) sorted lists into one sorted list, where \( n \) is the total number of elements in all the input lists. (Hint: Use a min-heap for \( k \)-way merging.)\\
\textbf{Solution:\\}
That is in total $n * O(\lg k) + O(k) + O(1)=O(n \lg k)$ based on Algorithm 5 below.
\begin{algorithm}
\caption{Min-Heapify}
\begin{algorithmic}[1]
\Function{Min-Heapify}{$A, i$}
    \State $l \gets \text{LEFT}(i)$
    \State $r \gets \text{RIGHT}(i)$
    \If {$l \leq A.\text{heap-size} \And A[l] < A[i]$}
        \State $smallest \gets l$
    \Else
        \State $smallest \gets i$
    \EndIf
    \If {$r \leq A.\text{heap-size} \And A[r] < A[smallest]$}
        \State $smallest \gets r$
    \EndIf
    \If {$smallest \neq i$}
        \State exchange $A[i]$ with $A[smallest]$
        \State \Call{Min-Heapify}{$A, smallest$}
    \EndIf
\EndFunction \Comment{$O(\lg n)$ Recall from CLRS.}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Build-Min-Heap}
\begin{algorithmic}[1]
\Function{Build-Min-Heap}{$A$}
    \State $A.heap\text{-}size = A.length$
    \For {$i = \lfloor A.length/2 \rfloor$ \textbf{downto} $1$}
        \State \Call{Min-Heapify}{$A, i$}
    \EndFor
\EndFunction \Comment{$O(n)$ Recall from CLRS.}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Heap Decrease Key and Min-Heap Insert}
\begin{algorithmic}[1]
\Function{Heap-Decrease-Key}{$A$, $i$, $key$}
    \If{$key > A[i]$}
        \State \textbf{error} ``new key is larger than current key''
    \EndIf
    \State $A[i] \gets key$
    \While{$i > 1$ \textbf{and} $A[\Call{Parent}{i}] > A[i]$}
        \State exchange $A[i]$ with $A[\Call{Parent}{i}]$
        \State $i \gets \Call{Parent}{i}$
    \EndWhile
\EndFunction \Comment{$O(\lg n)$ Recall from CLRS.}
\Statex
\Function{Min-Heap-Insert}{$A$, $key$}
    \State $A.heap\text{-}size \gets A.heap\text{-}size + 1$
    \State $A[A.heap\text{-}size] \gets \infty$
    \State \Call{Heap-Decrease-Key}{$A$, $A.heap\text{-}size$, $key$}
\EndFunction \Comment{$O(\lg n)$ Recall from CLRS.}
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{pop}
\begin{algorithmic}[1]
\Function{pop}{$A$}
    \If{$A.length < 1$}
        \State \textbf{error} there is nothing to pop in $A$
    \EndIf
    \State $X = A[1]$
    \State $A = A[2,...]$
    \State \Return $X$
\EndFunction \Comment{$O(1)$}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Merge-K-Lists}
\begin{algorithmic}[1]
\Function{Merge-K-Lists}{$A_1, A_2,..., A_k$}
    \State $C = []$ \Comment{$O(1)$}
    \State $B = [\Call{Pop}{A_1}, \Call{Pop}{A_2},..., \Call{Pop}{A_k}]$ \Comment{$k*O(1)$}
    \State \Call{Build-Min-Heap}{$B$} \Comment{$O(k)$}
    \While{$B.length \neq 0$} \Comment{pass all elements we are discussing in this question:$n$}
        \State $smallest = \Call{Pop}{B}$ \Comment{$O(1)$}
        \State $C = C\cup \{smallest\} $ \Comment{$O(1)$}
        \If{$A_{\text{smallest's origin}}$ is not empty}
            \State $nextElement = \Call{Pop}{A_{\text{smallest's origin}}}$ \Comment{$O(1)$}
            \State \Call{Min-Heap-Insert}{$B, nextElement$} \Comment{$O(\lg k)$}
        \EndIf
    \EndWhile
    \State \Return $C$ \Comment{$O(1)$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\pagebreak
\section*{Problem 4}
\textbf{Other versions of Selection.}\\
In the deterministic selection algorithm, the input elements are divided into groups of 5. Will the algorithm work in linear time if they are divided into:
\begin{enumerate}
    \item[a.] groups of 7?
    \item[b.] groups of 3?
\end{enumerate}
For each case, provide the worst-case running time.\\
\textbf{Solution:}
Recall from CLRS Page220-222, for groups of 5 case:
\begin{align*}
T(n) &\leq \left\{
\begin{aligned}
&O(1) && \text{if } n < 140 \\
&T(\left\lceil \frac{n}{5} \right\rceil) + T\left(\frac{7n}{10} + 6\right) + O(n) && \text{if } n \geq 140
\end{aligned}
\right.
\end{align*}
Where $T\left(\frac{7n}{10} + 6\right)$ comes from:
\begin{align}
    3 \left( \left\lceil \frac{1}{2} \left\lceil \frac{n}{5} \right\rceil\right\rceil  - 2 \right) \geq \frac{3n}{10} - 6
\end{align}
At least half of the $\left\lceil \frac{n}{5} \right\rceil$ groups contribute at least 3 elements that are greater than x, except for the one group that has fewer than 5 elements if 5 does not divide n exactly, and the one group containing x itself. Discounting these two groups, it follows that the number of elements greater than x is at least $\frac{3n}{10} - 6$. So for worst case, we assume all the rest is less than $x$ and doing \texttt{SELECT}. And 140 is just a guess, so we can skip the guess temporally.\\\\
Think about groups of $k$. (1) becomes (2) in general:
\begin{align}
     \left\lceil \frac{k}{2} \right\rceil\left( \left\lceil \frac{1}{2} \left\lceil \frac{n}{k} \right\rceil\right\rceil  - 2 \right) \geq \frac{n}{4} - k
\end{align}
At least $\frac{n}{4} - k$ are less than $x$, so at most $\frac{3n}{4} + k$ are greater than $x$.\\
So when $n$ is greater than some constant, we have $T(n) \leq T(\left\lceil \frac{n}{k} \right\rceil) + T(\frac{3n}{4} + k) + O(n)$. Doing some substitution:
\begin{align*}
    T(n) &\leq T(\left\lceil \frac{n}{k} \right\rceil) + T(\frac{3n}{4} + k) + O(n)\\
    &\leq c\left\lceil \frac{n}{k} \right\rceil + c(\frac{3n}{4} + k) +an\\
    &\leq \frac{cn}{k} + c(\frac{3n}{4} + k) +an\\
    &= cn + (\frac{-cn}{4}+\frac{cn}{k}+ck+an)\\
    &\leq cn
\end{align*}
The last step holds if $\frac{-cn}{4}+\frac{cn}{k}+ck+an \leq 0$, which is $c(-\frac{n}{4}+\frac{n}{k}+k)+an \leq 0$. As $c$ and $a$ are positive integers, it could be $-\frac{n}{4}+\frac{n}{k}+k \leq 0$. Let $-\frac{n}{4}+\frac{n}{k}+k=f(k)$. We can see that $f(4)=4>0$, $f(5)=-\frac{n}{20}+5\leq0$ when $n \geq 100$. So we can always find a $n_0$ such that $f(k) \leq 0$ when $k>5$. When $T(n)\leq cn$, the running time is linear. So, groups of 7 runs linear time but groups of 3 does not.($T(n)=T(n/3)+T(\frac{2n}{3})+O(n)$ is $\Theta(n \lg n)$).
\section*{Problem 5}
\textbf{Weighted medians} CLRS 9-2\\
For \( n \) distinct elements \( x_1, x_2, \ldots, x_n \) with positive weights \( w_1, w_2, \ldots, w_n \) such that \( \sum_{i=1}^{n} w_i = 1 \), the \textbf{weighted (lower) median} is the element \( x_k \) satisfying

\[
\sum_{\substack{x_i < x_k}} w_i < \frac{1}{2}
\]

and

\[
\sum_{\substack{x_i > x_k}} w_i \leq \frac{1}{2}.
\]

For example, if the elements are 0.1, 0.35, 0.05, 0.1, 0.15, 0.05, 0.2 and each element equals its weight (that is, \( w_i = x_i \) for \( i = 1, 2, \ldots, 7 \)), then the median is 0.1, but the weighted median is 0.2.

\begin{enumerate}
    \item[a.] Argue that the median of \( x_1, x_2, \ldots, x_n \) is the weighted median of the \( x_i \) with weights \( w_i = \frac{1}{n} \) for \( i = 1, 2, \ldots, n \).
    \item[b.] Show how to compute the weighted median of \( n \) elements in \( O(n \lg n) \) worst-case time using sorting.
    \item[c.] Show how to compute the weighted median in \( \Theta(n) \) worst-case time using a linear-time median algorithm such as SELECT from Section 9.3.
\end{enumerate}

The \textbf{post-office location problem} is defined as follows. We are given \( n \) points \( p_1, p_2, \ldots, p_n \) with associated weights \( w_1, w_2, \ldots, w_n \). We wish to find a point \( p \) (not necessarily one of the input points) that minimizes the sum \( \sum_{i=1}^{n} w_i d(p, p_i) \), where \( d(a, b) \) is the distance between points \( a \) and \( b \).

\begin{enumerate}
    \item[d.] Argue that the weighted median is a best solution for the 1-dimensional post-office location problem, in which points are simply real numbers and the distance between points \( a \) and \( b \) is \( d(a, b) = |a - b| \).
    \item[e.] Find the best solution for the 2-dimensional post-office location problem, in which the points are \( (x, y) \) coordinate pairs and the distance between points \( a = (x_1, y_1) \) and \( b = (x_2, y_2) \) is the \textbf{Manhattan distance} given by \( d(a, b) = |x_1 - x_2| + |y_1 - y_2| \).
\end{enumerate}
\textbf{Solution:}
\begin{enumerate}
    \item[a.] When $x_1,...,x_n$ are weighted equally where $w_i=\frac{1}{n}$ for $i=1,...n$, assume $n$ is odd first. The median $x_i=x_{\frac{n+1}{2}}$, $x_{i-1}=x_{\frac{n-1}{2}}$, where $\sum_{i=1}^{\frac{n-1}{2}} \frac{1}{n} = \frac{n-1}{2n} < 1/2$ and $\sum_{i=\frac{n+3}{2}}^{n} \frac{1}{n} = \frac{n-1}{2n} \leq 1/2$ satisfies $x_i$ is also the weighted median. Assume $n$ is even, The median $x_i=x_{\frac{n}{2}}$. It is obvious that $\sum_{i=1}^{\frac{n}{2}} \frac{1}{n}=\sum_{i=\frac{n+1}{2}}^{n} \frac{1}{n}=\frac{1}{2}$. So the sum of the weights before $x_i$ is $\frac{1}{2}-\frac{1}{n} < \frac{1}{2}$.
    \item[b.]
    \begin{algorithm}
    \caption{Weighted-median}
    \begin{algorithmic}[1]
    \Function{Weighted-median}{$x_1, x_2,..., x_n$}
        \State $w=0$
        \State \Call{Heap-Sort}{$x_1, x_2,..., x_n$} \Comment{$O(n \lg n)$}
        \For{$i=1$ \textbf{upto} $n-1$} \Comment{$n*O(1)$}
            \State $w = w + x_i$
            \If{$w > \frac{1}{2}$}
                \State \Return $x_i$
            \EndIf
        \EndFor
    \EndFunction \Comment{$O(n \lg n)+O(n)=O(n \lg n)$}
\end{algorithmic}
\end{algorithm}
    \item[c.]
    We can use the \texttt{SELECT} function below, where \texttt{MEDIAN} is doing similarly as CLRS 9.3 and Problem 4, based on the size of n, we can then choose how many groups to divide.
    \begin{algorithm}
    \caption{Sum}
    \begin{algorithmic}[1]
    \Function{Sum}{$A$}
    \State $total = 0$
    \For{$i=1 \textbf{ upto } n$}
        \State $total=total+A[i]$
    \EndFor
    \EndFunction \Comment{$O(n)$}
    \end{algorithmic}
    \end{algorithm} 
    
    \begin{algorithm}
    \caption{Weighted-median}
    \begin{algorithmic}[1]
    \Function{Weighted-median}{$A$, $i$, $n$}
    \If{$n = 1$}
        \State \Return $A[1]$
    \EndIf
    \State $p \gets \Call{Median}{A}$
    \State $L \gets \{x \in A : x \leq p\}$
    \State $H \gets \{x \in A : x > p\}$
    \State $temp \gets \Call{Sum}{L}$
    \If{$i \leq temp$}
        \State \Return $\Call{Select}{L, i, \lvert L \rvert}$
    \Else
        \State \Return $\Call{Select}{H, i - temp, \lvert H \rvert}$
    \EndIf
    \EndFunction \Comment{Similar as \texttt{SELECT} function we seen before, $\Theta(n)$}
    \end{algorithmic}
    \end{algorithm}
    
    \pagebreak
    \item[d.] Let $p$ be the minimizer, and suppose that $p$ is not the weighted mean. And let $\epsilon>0$ where $\epsilon=\min_i(\lvert p-p_i \rvert)$ and $p_m>p$.
    Then we have:
    \[
    \sum_{i=1}^{n} w_i d(p + \epsilon, p_i) = \sum_{i=1}^{n} w_i d(p, p_i) + \epsilon \left( \sum_{p_i < p} w_i - \sum_{p_i > p} w_i \right) < \sum_{i=1}^{n} w_i d(p, p_i)
    \]
    Since for $p_m$, $\sum_{p_i < p_m} w_i \leq \sum_{p_i > p_m} w_i$ and $p_m>p$, so $\sum_{p_i < p} w_i - \sum_{p_i > p} w_i < 0$. Then we find out another minimizer, which contradicts the assumption.
    \item[e.] Manhattan distance is just 2-d variation of part(d.):
    \[
    \sum_{i=1}^{n} w_i d(p, p_i) = \sum_{i=1}^{n} w_i |p_x - (p_i)_x| + \sum_{i=1}^{n} w_i |p_y - (p_i)_y|.
    \]
    It will suffice to minimize each sum separately, which we can do since we choose $p_x$ and $p_y$ individually. The optimal answer here is $p=(p_x,p_y)$ where $p_x$ is the weighted mean of the $x$-coordinates of the $p_i$'s and $p_y$ is the weighted mean of the $y$-coordinates of the $p_j$'s.
\end{enumerate}
\end{document}
